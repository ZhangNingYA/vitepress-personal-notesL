---
title: 第25讲：对称矩阵与正定性（重点梳理）
date: 2025-12-21
---

## 第25讲：对称矩阵与正定性（重点梳理）

> Lecture 25: Symmetric matrices and positive definiteness  
> 主线：对称矩阵是“最重要的一类矩阵”；它把我们学过的消元（pivots）、行列式（determinants）与特征值（eigenvalues）强力串起来。  
> 关键词：real eigenvalues、orthogonal eigenvectors、spectral theorem、pivots 与 eigenvalues 的符号关系、positive definite 的快速判别。

---

## 0. 本讲要解决的问题（你应该带走什么）

1) **对称矩阵的特征结构为什么“特别好”**  
- 为什么对称矩阵的特征值一定是实数？  
- 为什么不同特征值对应的特征向量彼此正交，并且可以选成标准正交基？

2) **对称矩阵的“标准分解”是什么**（把特征信息直接摆在脸上）  
- 为什么对称矩阵可以写成 $A = Q\Lambda Q^T$，而不是一般矩阵的 $A=S\Lambda S^{-1}$？

3) **不显式求特征值，也能判断正负性**  
- 为什么对称矩阵里，“pivot 的符号个数”=“特征值的符号个数”？  
- 由此怎么引出/定义 **正定矩阵（positive definite）**，以及快速判别法？

---

## 1. 老师怎么引入的（Lecture 的开场逻辑）

老师一上来就把主结论先说出来：对称矩阵 $A=A^T$ 的两条核心性质是：

- 特征值是实数；
- 特征向量可以选成彼此正交（更准确：可以选成一组正交归一的特征向量）。

并把它和上一讲的 Markov 矩阵类比：  
Markov 矩阵有 $\lambda=1$；对称矩阵则对 eigen-structure 有“强约束”。

---

## 2. 例子与讨论（老师用来“落地”的典型点）

### 2.1 “反例式提醒”：单位矩阵 $I$
$A=I$ 是对称矩阵；特征值全是 1。  
但“特征向量都正交”这句话要小心：对 $I$ 来说 **任何向量都是特征向量**。  
因此更准确的表达是：

- 对称矩阵的特征向量 **可以被选择** 为正交的（尤其在重特征值出现时，有一个维数更高的特征子空间，你可以在里面选一组正交基）。

---

## 3. 对称矩阵的关键结论 1：谱定理（Spectral Theorem）

### 3.1 一般情形回顾
一般可对角化矩阵：
$$
A = S\Lambda S^{-1},
$$
其中 $S$ 的列是特征向量。

### 3.2 对称矩阵的加强版（最关键的升级）
对称矩阵可以把特征向量选成正交归一，于是 $S$ 变成正交矩阵 $Q$，并且
$$
Q^{-1}=Q^T.
$$

所以得到对称矩阵的标准分解：
$$
A = Q\Lambda Q^T.
$$

这就是本讲反复强调的 **spectral theorem**：  
- $\Lambda$ 把特征值（spectrum）放在对角线上；  
- $Q$ 把特征向量放在列上，并且列向量两两正交、长度为 1。

---

## 4. 对称矩阵的关键结论 2：为什么特征值一定是实数（证明思路）

老师的证明策略是从特征方程出发：
$$
Ax=\lambda x
$$
先允许 $\lambda,x$ 可能是复数，然后引入“转置 + 共轭”的内积结构，利用对称性把左右两边构造成同一个标量表达式，推出 $\lambda=\overline{\lambda}$，从而 $\lambda$ 为实数。

你可以把这个证明理解为：  
对称性让“内积形式”非常干净，从而把复数的虚部逼掉。

---

## 5. 一个非常实用的桥：pivots 的符号 vs eigenvalues 的符号

### 5.1 问题动机
对称矩阵的特征值是实数，于是我们关心它们是正是负（例如稳定性）。  
但直接求一个大矩阵的全部特征值很难。

### 5.2 关键事实（老师强调“非常有用”）
对称矩阵中：

- 正 pivot 的个数 = 正特征值的个数  
- 负 pivot 的个数 = 负特征值的个数

（直观用途：不用算全部特征值，只要做消元看 pivots 的符号，就能知道有多少正/负特征值。）

老师还提到一个“移位”的想法：  
如果你看 $A-7I$ 的 pivots 符号，就能知道 $A$ 的特征值有多少个在 7 的上方/下方（因为移位会把所有特征值整体平移）。

---

## 6. 引出正定矩阵（Positive Definite）

### 6.1 定义（本讲口径）
正定矩阵（positive definite）是对称矩阵的一个“最优秀子类”：
- $A$ 对称；
- 所有特征值都为正。

因此，按照第 5 节的符号对应关系，正定矩阵也等价于：
- 所有 pivots 都为正（在对称消元的语境下）。

### 6.2 老师给的 2×2 数字例子（用于对比“pivots 更容易”）
老师给出一个对称矩阵（以 2×2 为主）：
$$
A=\begin{bmatrix}5&3\\3&2\end{bmatrix}.
$$

- pivot 很快：$p_1=5$，且 $\det(A)=11$，所以
$$
p_1p_2=\det(A)\Rightarrow p_2=\frac{11}{5}>0.
$$
因此两个 pivots 都为正，从而两个特征值都为正。

- 若硬算特征值：用迹与行列式得到特征多项式
$$
\lambda^2 - (\operatorname{tr}A)\lambda + \det(A)=0,
$$
其中 $\operatorname{tr}A=7$，$\det(A)=11$。

老师借此强调：对 2×2 还行，但维数大时“pivots 更香”。

### 6.3 仅“determinant > 0”不够：需要一串“子行列式”
老师还提醒：$\det(A)>0$ 并不保证正定。  
例如
$$
\begin{bmatrix}-1&\cdot\\ \cdot&-3\end{bmatrix}
$$
可能整体行列式为正，但 pivots（以及特征值）仍可能为负。

因此需要检查“一连串从左上角开始的子行列式”（也可理解为 leading principal minors）：
- 1×1、2×2、…、n×n 都要为正，才是正定。

---

## 7. 一句话复盘（把课连起来）

对称矩阵把“特征分解”和“正交”合并成 $A=Q\Lambda Q^T$；  
再把“消元的 pivots”与“特征值的正负”挂钩，于是正定性可以用 pivots/子行列式快速判别。  
这就是老师说的“课程开始汇合”的关键节点之一。

---

## 参考来源（便于你对照原始材料）
- MIT OCW Lecture 25 页面（标题与讲次说明）：https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/resources/lecture-25-symmetric-matrices-and-positive-definiteness/
- Lecture 25 官方 transcript（PDF）：https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/16edaa6071e4c657f7426e85c6d757e7_MIT18_06S10_L25.pdf
